{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzZbt5ZHK2vP",
        "outputId": "551853ec-9c71-4479-ce25-2026042c59a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m80.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m74.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.107-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.20.1+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.107-py3-none-any.whl (974 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m974.5/974.5 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.107 ultralytics-thop-2.0.14\n"
          ]
        }
      ],
      "source": [
        "# Install the required packages\n",
        "!pip install torch torchvision torchaudio\n",
        "!pip install ultralytics\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PVn2jP-K6xv",
        "outputId": "4abe876c-86cf-4cc3-f6f2-96ed9ac7fae9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Path to your zip file in Google Drive\n",
        "zip_path = '/content/drive/MyDrive/All/All.zip'  # Adjust path if needed\n",
        "\n",
        "# Destination where the zip will be extracted\n",
        "extract_path = '/content/dataset/'\n",
        "\n",
        "# Unzip the file\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(\"Dataset unzipped successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2R4kHeVzLm9a",
        "outputId": "498a84f3-ca1a-46a6-cd23-a47328e72417"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset unzipped successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List files in the extracted dataset folder\n",
        "os.listdir(extract_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rZH-00HM05v",
        "outputId": "3ff96cd5-9c28-49bf-a4ac-a20768a712f6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['All']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the content of the yaml file\n",
        "yaml_path = '/content/dataset/All/data.yaml'  # Adjust this path\n",
        "with open(yaml_path, 'r') as file:\n",
        "    print(file.read())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbJyL-XlM3VW",
        "outputId": "9e6e54b9-4b0d-420f-adbe-f60765b5ee90"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train:\n",
            "  - ../train/images\n",
            "val:\n",
            "  - ../valid/images\n",
            "test:\n",
            "  - ../test/images\n",
            "nc: 183\n",
            "names:\n",
            "  '0': gun\n",
            "  '1': Aggressor\n",
            "  '2': Discussion_WGI\n",
            "  '3': Discussions_WOBoard\n",
            "  '4': Discussions_ppl\n",
            "  '5': Hand\n",
            "  '6': Item_passed\n",
            "  '7': Knife_Deploy\n",
            "  '8': Knife_Weapon\n",
            "  '9': NonViolence\n",
            "  '10': Person\n",
            "  '11': Stabbing\n",
            "  '12': Victim\n",
            "  '13': Violence\n",
            "  '14': Writing_Board\n",
            "  '15': hang\n",
            "  '16': book\n",
            "  '17': AC\n",
            "  '18': Bathtub\n",
            "  '19': Bed Frame\n",
            "  '20': Bed\n",
            "  '21': Closet\n",
            "  '22': Cupboard\n",
            "  '23': Desk\n",
            "  '24': Dining Table\n",
            "  '25': Dish Washer\n",
            "  '26': Door\n",
            "  '27': Exhaust Fan\n",
            "  '28': Exhaust Hood\n",
            "  '29': Faucet\n",
            "  '30': Fridge\n",
            "  '31': Microwave\n",
            "  '32': Oven\n",
            "  '33': Sink\n",
            "  '34': Sofa\n",
            "  '35': Stove\n",
            "  '36': TV\n",
            "  '37': Thermo Ventilator\n",
            "  '38': Toilet Sink\n",
            "  '39': Toilet\n",
            "  '40': Washing Machine\n",
            "  '41': Water Cubicle\n",
            "  '42': Water Heater\n",
            "  '43': Windowsill\n",
            "  '44': knife\n",
            "  '45': pistol\n",
            "  '46': ceiling-fan\n",
            "  '47': close door\n",
            "  '48': fan\n",
            "  '49': light\n",
            "  '50': open-door\n",
            "  '51': 2-Piece-Sectional-Sofa\n",
            "  '52': 4-Piece-Sectional-Sofa\n",
            "  '53': Armchair\n",
            "  '54': BBQ\n",
            "  '55': Bahut\n",
            "  '56': BeanBag-Chair\n",
            "  '57': Bedside-Table\n",
            "  '58': Bench-Chair\n",
            "  '59': Big-Bed\n",
            "  '60': Bike\n",
            "  '61': Bunk-Bed\n",
            "  '62': Carpet\n",
            "  '63': Chandelier\n",
            "  '64': Child-Bed\n",
            "  '65': Coat-Stand\n",
            "  '66': Desk\n",
            "  '67': Desktop\n",
            "  '68': Dishwasher\n",
            "  '69': Display-Cabinet\n",
            "  '70': Dressing-Table\n",
            "  '71': EV-Charger\n",
            "  '72': Egg-Chair\n",
            "  '73': Electronic-Piano\n",
            "  '74': Exercise-Bench\n",
            "  '75': Exercise-Bike\n",
            "  '76': Exercise-Treadmill\n",
            "  '77': FileDrawer-Storage\n",
            "  '78': Flat-TV\n",
            "  '79': Floor-Lamp\n",
            "  '80': Freezer\n",
            "  '81': Fridge\n",
            "  '82': Game-Table\n",
            "  '83': Gueridon\n",
            "  '84': Guitar\n",
            "  '85': HI-FI\n",
            "  '86': Hot-Tub\n",
            "  '87': Ironing-Board\n",
            "  '88': Ladder\n",
            "  '89': Laundry-Basket\n",
            "  '90': Lawn-Mower\n",
            "  '91': Luggage\n",
            "  '92': Microwave\n",
            "  '93': Mirror\n",
            "  '94': Office-Chair\n",
            "  '95': Ottoman-Chair\n",
            "  '96': Oven\n",
            "  '97': Painting\n",
            "  '98': Papasan-Chair\n",
            "  '99': Piano\n",
            "  '100': Plants\n",
            "  '101': Power-Tool\n",
            "  '102': Printer\n",
            "  '103': Shelve-Storage\n",
            "  '104': Shoe-Rack\n",
            "  '105': Side-Table\n",
            "  '106': Sideboard-Credenza-Storage\n",
            "  '107': Standard-Chair\n",
            "  '108': Standard-Safe\n",
            "  '109': Standard-Sofa\n",
            "  '110': Standard-Table\n",
            "  '111': Stool\n",
            "  '112': Sun-Lounger\n",
            "  '113': TV-Stand\n",
            "  '114': Table-Lamp\n",
            "  '115': Table-Umbrella\n",
            "  '116': Tool-Box\n",
            "  '117': Tractor-Mower\n",
            "  '118': Tumble-Dryer\n",
            "  '119': Twin-Bed\n",
            "  '120': Vacuum-Cleaner\n",
            "  '121': Wardrobe\n",
            "  '122': Washing-Machine\n",
            "  '123': Wine-Rack\n",
            "  '124': Gunting\n",
            "  '125': laptop\n",
            "  '126': Gray Scale Yapma - v17 2024-12-16 10-49pm\n",
            "  '127': undefined\n",
            "  '128': fire\n",
            "  '129': other\n",
            "  '130': smoke\n",
            "  '131': cat-Abyssinian\n",
            "  '132': cat-Bengal\n",
            "  '133': cat-Birman\n",
            "  '134': cat-Bombay\n",
            "  '135': cat-British_Shorthair\n",
            "  '136': cat-Egyptian_Mau\n",
            "  '137': cat-Maine_Coon\n",
            "  '138': cat-Persian\n",
            "  '139': cat-Ragdoll\n",
            "  '140': cat-Russian_Blue\n",
            "  '141': cat-Siamese\n",
            "  '142': cat-Sphynx\n",
            "  '143': dog-american_bulldog\n",
            "  '144': dog-american_pit_bull_terrier\n",
            "  '145': dog-basset_hound\n",
            "  '146': dog-beagle\n",
            "  '147': dog-boxer\n",
            "  '148': dog-chihuahua\n",
            "  '149': dog-english_cocker_spaniel\n",
            "  '150': dog-english_setter\n",
            "  '151': dog-german_shorthaired\n",
            "  '152': dog-great_pyrenees\n",
            "  '153': dog-havanese\n",
            "  '154': dog-japanese_chin\n",
            "  '155': dog-keeshond\n",
            "  '156': dog-leonberger\n",
            "  '157': dog-miniature_pinscher\n",
            "  '158': dog-newfoundland\n",
            "  '159': dog-pomeranian\n",
            "  '160': dog-pug\n",
            "  '161': dog-saint_bernard\n",
            "  '162': dog-samoyed\n",
            "  '163': dog-scottish_terrier\n",
            "  '164': dog-shiba_inu\n",
            "  '165': dog-staffordshire_bull_terrier\n",
            "  '166': dog-wheaten_terrier\n",
            "  '167': dog-yorkshire_terrier\n",
            "  '168': person\n",
            "  '169': burned socket\n",
            "  '170': damage wire\n",
            "  '171': overloaded socket\n",
            "  '172': Socket\n",
            "  '173': Door Close\n",
            "  '174': Door Open\n",
            "  '175': Package\n",
            "  '176': plants\n",
            "  '177': WeeeTest1 - v1 2024-07-07 3-17pm\n",
            "  '178': smoke\n",
            "  '179': toy\n",
            "  '180': broken-glass\n",
            "  '181': spill\n",
            "  '182': extension - v1 2025-03-26 11-03am\n",
            "  '183': object\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "\n",
        "# Load the yaml file\n",
        "yaml_file_path = '/content/dataset/All/data.yaml'\n",
        "\n",
        "with open(yaml_file_path, 'r') as file:\n",
        "    data = yaml.safe_load(file)\n",
        "\n",
        "# Check the number of class names\n",
        "num_classes = len(data['names'])\n",
        "print(f\"Number of classes: {num_classes}\")\n",
        "\n",
        "# Update 'nc' if necessary\n",
        "data['nc'] = num_classes\n",
        "\n",
        "# Save the updated YAML file\n",
        "with open(yaml_file_path, 'w') as file:\n",
        "    yaml.dump(data, file)\n",
        "\n",
        "print(\"YAML file updated successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yl2jlBIMNU51",
        "outputId": "1d30d341-e617-4527-8ac1-0ddde9d09c42"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of classes: 184\n",
            "YAML file updated successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load the YOLOv8 model\n",
        "model = YOLO('yolov8n.pt')  # You can choose the model type depending on your requirement\n",
        "\n",
        "# Start training\n",
        "model.train(\n",
        "    data=yaml_path,  # Path to your yaml file\n",
        "    epochs=100,  # Total epochs\n",
        "    batch=16,  # Adjust batch size if necessary\n",
        "    imgsz=640,  # Image size for training\n",
        "    project='/content/ultralytics/runs/train',  # Path to save results\n",
        "    name='custom_yolov8',  # Name for the training run\n",
        "    save_period=10  # Save model after every 10 epochs\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-pm8W4RNCRE",
        "outputId": "7117670e-61ba-4d5c-a6a7-2f9c60b4584b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.107 🚀 Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/content/dataset/All/data.yaml, epochs=100, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=10, cache=False, device=None, workers=8, project=/content/ultralytics/runs/train, name=custom_yolov83, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/content/ultralytics/runs/train/custom_yolov83\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 755k/755k [00:00<00:00, 19.9MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overriding model.yaml nc=80 with nc=184\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1   1112056  ultralytics.nn.modules.head.Detect           [184, [64, 128, 256]]         \n",
            "Model summary: 129 layers, 3,371,592 parameters, 3,371,576 gradients, 9.9 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/ultralytics/runs/train/custom_yolov83', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.35M/5.35M [00:00<00:00, 98.7MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/dataset/All/train/labels... 152674 images, 6022 backgrounds, 0 corrupt: 100%|██████████| 152674/152674 [03:37<00:00, 701.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/dataset/All/train/images/2007_000187_jpg.rf.6072bb3923494a7afb8648ba483324fd.jpg: 23 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/dataset/All/train/images/2007_000999_jpg.rf.6c08f70e15d4b331a62dd733f71a31ef.jpg: 7 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/dataset/All/train/images/2007_002260_jpg.rf.67b39e42171c963a3427b19a2abe68b4.jpg: 19 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/dataset/All/train/images/2008_003417_jpg.rf.f31d813882efbf61f9f5526453e177e3.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/dataset/All/train/images/2008_003522_jpg.rf.0c7864f40841e847ba3fb26e08efd3e3.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/dataset/All/train/images/2008_006554_jpg.rf.f803f4b634de852ff949e04c8e89ced5.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/dataset/All/train/images/2009_002733_jpg.rf.a2dac53f2d02cd54c047dc7af456e088.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/dataset/All/train/images/20240221_103249_jpg.rf.675240171cde05b44f96fdbe83dcdabd.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/dataset/All/train/images/20240221_103249_jpg.rf.81469627acf6ac035292133fe6bf4be1.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/dataset/All/train/images/20240221_103249_jpg.rf.b41f2b28d578cdeeadcb467681b41ac3.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/dataset/All/train/images/IMG_1401_jpg.rf.34c5c503b17b785ce440a92584b6a94f.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/dataset/All/train/images/IMG_1401_jpg.rf.6ab5ff37567dc71a81ddc57f044c5d7c.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/dataset/All/train/images/IMG_1401_jpg.rf.a4880b79afee06dd4e26552b839d3dcc.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/dataset/All/train/images/IMG_2967_jpg.rf.202e9edcca2e0cb7ed6b0b15665bdc8c.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/dataset/All/train/images/IMG_2967_jpg.rf.5645c00f7427ec20ae340ee3904a76cc.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/dataset/All/train/images/IMG_2967_jpg.rf.b3232ded63a3bf87ab98a254ff80a267.jpg: 1 duplicate labels removed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/dataset/All/train/labels.cache\n",
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 245610, len(boxes) = 525397. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/dataset/All/valid/labels... 31197 images, 2694 backgrounds, 0 corrupt: 100%|██████████| 31197/31197 [00:28<00:00, 1108.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/All/valid/images/20240221_103329_jpg.rf.55e749bc6ff93f4ec5b83098d89c4a56.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/dataset/All/valid/images/GX010023_frame_00025_right_jpg.rf.3255febc597d78d5d6e4bde455ba7b2a.jpg: 23 duplicate labels removed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/dataset/All/valid/labels.cache\n",
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 24359, len(boxes) = 67073. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "Plotting labels to /content/ultralytics/runs/train/custom_yolov83/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/ultralytics/runs/train/custom_yolov83\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      1/100       2.9G      1.617        5.4      1.613         93        640:   3%|▎         | 313/9543 [01:50<43:13,  3.56it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save Model Checkpoints During Training:\n",
        "Ensure that you have the save_period set to the number of epochs you want to save the model every (for example, every 10 epochs)."
      ],
      "metadata": {
        "id": "_F7YCFgmO6sr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.train(\n",
        "    data='/content/dataset/All/data.yaml',\n",
        "    epochs=100,\n",
        "    batch=16,\n",
        "    imgsz=640,\n",
        "    save=True,\n",
        "    save_period=10,  # Save the model every 10 epochs\n",
        "    project='/content/ultralytics/runs/train',\n",
        "    name='custom_yolov8',\n",
        "    pretrained=True,\n",
        ")\n"
      ],
      "metadata": {
        "id": "pwSYbrfjO5DH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "/content/ultralytics/runs/train/custom_yolov8/weights/\n"
      ],
      "metadata": {
        "id": "XqffmlTIO-pV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Resuming Training from the Latest Weights:\n",
        "When you return to the session after it gets interrupted, find the latest checkpoint file (for example, epoch_30.pt) in the /weights directory.\n",
        "\n",
        "To resume training from the latest checkpoint (for example, epoch_30.pt), run the following code:"
      ],
      "metadata": {
        "id": "XhGPQ4PvPAza"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load the YOLOv8 model and specify the checkpoint to resume training from\n",
        "model = YOLO('/content/ultralytics/runs/train/custom_yolov8/weights/epoch_30.pt')\n",
        "\n",
        "# Continue training from epoch 30\n",
        "model.train(\n",
        "    data='/content/dataset/All/data.yaml',\n",
        "    epochs=100,  # Set the total epochs for resuming, counting from the checkpoint epoch\n",
        "    batch=16,\n",
        "    imgsz=640,\n",
        "    save=True,\n",
        "    save_period=10,  # Save the model every 10 epochs\n",
        "    project='/content/ultralytics/runs/train',\n",
        "    name='custom_yolov8',\n",
        "    pretrained=False,  # Don't use pretrained weights, continue with the checkpoint\n",
        ")\n"
      ],
      "metadata": {
        "id": "mymRz-Q5O--e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Downloading the Latest Model Checkpoint:\n",
        "If you'd like to download the latest weights (e.g., epoch_30.pt), run this command in Colab:"
      ],
      "metadata": {
        "id": "tq9aVFPlPCpD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Path to the model checkpoint\n",
        "checkpoint_path = '/content/ultralytics/runs/train/custom_yolov8/weights/epoch_30.pt'\n",
        "\n",
        "# Move the checkpoint to a download-friendly folder\n",
        "shutil.move(checkpoint_path, '/content/epoch_30.pt')\n"
      ],
      "metadata": {
        "id": "cC9x3uH7PEVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Resuming Training on a New Colab Session:\n",
        "If your session is completely terminated, you’ll need to:\n",
        "\n",
        "Upload the model checkpoint (epoch_30.pt or whatever the latest epoch is) from your local system back to Colab, using the file upload option.\n",
        "\n",
        "Specify the path to the uploaded checkpoint file when resuming training."
      ],
      "metadata": {
        "id": "ZhLf-yuEPFa3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load the YOLOv8 model from the checkpoint (e.g., epoch_30.pt)\n",
        "model = YOLO('/content/epoch_30.pt')  # Specify the path to the uploaded checkpoint file\n",
        "\n",
        "# Resume training from epoch 30\n",
        "model.train(\n",
        "    data='/content/dataset/All/data.yaml',\n",
        "    epochs=100,  # Set the total epochs to resume from where you left off\n",
        "    batch=16,\n",
        "    imgsz=640,\n",
        "    save=True,\n",
        "    save_period=10,  # Save the model every 10 epochs\n",
        "    project='/content/ultralytics/runs/train',\n",
        "    name='custom_yolov8',\n",
        "    pretrained=False,  # Continue with the checkpoint\n",
        ")\n"
      ],
      "metadata": {
        "id": "_ucF9Ap8PHAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summary:\n",
        "Save checkpoints during training with save_period.\n",
        "\n",
        "Resume training from the latest checkpoint using model = YOLO('path/to/checkpoint.pt').\n",
        "\n",
        "Download checkpoints to your local machine if needed for later use.\n",
        "\n",
        "This method will let you seamlessly continue training from where it left off after interruptions.\n",
        "\n"
      ],
      "metadata": {
        "id": "QOZgz9ATPINk"
      }
    }
  ]
}